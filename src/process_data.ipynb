{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from config import (\n",
    "    WITHHELD_DEMOGRAPHIC_FEATURES,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    VOTER_FILE_DIR,\n",
    "    VOTER_FILE_COLUMN_MAPPING_FILE,\n",
    "    ELECTION_DATES_TO_NAMES_MAPPING_FILE,\n",
    "    FEATURES_FILE,\n",
    "    VOTER_FILE_STR,\n",
    "    ZONE_CODES_STR,\n",
    "    ZONE_TYPES_STR,\n",
    "    ELECTION_MAP_STR,\n",
    "    TEN_PCT_SAMPLE_FILE,\n",
    "    election_date_to_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The goal of this script is to take the raw Pennsylvania voter file and process it into usable tabular data.\n",
    "\n",
    "### Pre-processing\n",
    "The dataset is split along county lines, so let's first simply gather a list of the counties in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67 counties\n"
     ]
    }
   ],
   "source": [
    "# Find the names of all the counties\n",
    "counties: set[str] = set()\n",
    "for file in sorted(os.listdir(VOTER_FILE_DIR)):\n",
    "    if VOTER_FILE_STR in file:\n",
    "        counties.add(file.split(\" \")[0])\n",
    "\n",
    "print(f\"Found {len(counties)} counties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset also has messy election data. Some elections are specific to small areas (like special elections), and some have differing descriptions across counties. We'll deal with all this later, but for now, let's find all the unique election dates and the different descriptions they have across counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83 different election dates, with a minimum of 1 and a maximum of 27 descriptions\n"
     ]
    }
   ],
   "source": [
    "# Track the dates of elections, and their corresponding descriptions\n",
    "date_to_names: dict[str, set[str]] = {}\n",
    "for file in os.listdir(VOTER_FILE_DIR):\n",
    "    if ELECTION_MAP_STR in file:\n",
    "        election_map = pd.read_csv(\n",
    "            os.path.join(VOTER_FILE_DIR, file),\n",
    "            sep=\"\\t\",\n",
    "            encoding=\"unicode_escape\",\n",
    "            header=None,\n",
    "        )\n",
    "\n",
    "        # Store the description of each election for this county\n",
    "        for _, row in election_map.iterrows():\n",
    "            if row[3] not in date_to_names:\n",
    "                date_to_names[row[3]] = {row[2]}\n",
    "            else:\n",
    "                date_to_names[row[3]].add(row[2])\n",
    "\n",
    "date_to_names = {date: list(date_to_names[date]) for date in date_to_names}\n",
    "json.dump(\n",
    "    date_to_names,\n",
    "    open(ELECTION_DATES_TO_NAMES_MAPPING_FILE, \"w\"),\n",
    "    indent=4,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(date_to_names)} different election dates, with a minimum of {min([len(date_to_names[date]) for date in date_to_names])} and a maximum of {max([len(date_to_names[date]) for date in date_to_names])} descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the actual columns we'll use in our final dataset. The columns are contain both demographic data and election history for each voter. So, let's define the specific column names and make the edits we need (like converting to one-hot encoding, adding feature presence columns, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_template = pd.read_csv(VOTER_FILE_COLUMN_MAPPING_FILE, header=0)\n",
    "\n",
    "# Define the column names which will store election information\n",
    "election_column_names = []\n",
    "for election in date_to_names.keys():\n",
    "    election_column_names.extend(election_date_to_feature_names(election))\n",
    "\n",
    "# Only include up to the column named District 40\n",
    "raw_column_names = columns_template[\"Field Description\"].tolist()\n",
    "demographic_columns = [\n",
    "    col\n",
    "    for col in raw_column_names\n",
    "    if \"Election\" not in col\n",
    "    and \"District\" not in col\n",
    "    and col not in WITHHELD_DEMOGRAPHIC_FEATURES\n",
    "]\n",
    "\n",
    "# Replace some specific columns with one-hot encodings, and add feature presence columns where needed\n",
    "demographic_columns.remove(\"Gender\")\n",
    "demographic_columns.append(\"Gender M\")\n",
    "demographic_columns.append(\"Gender F\")\n",
    "demographic_columns.append(\"Gender U\")\n",
    "\n",
    "demographic_columns.remove(\"Party Code\")\n",
    "demographic_columns.append(\"Party D\")\n",
    "demographic_columns.append(\"Party R\")\n",
    "demographic_columns.append(\"Party I\")\n",
    "\n",
    "demographic_columns.remove(\"Last Vote Date\")\n",
    "demographic_columns.append(\"Last Vote Date Presence\")\n",
    "demographic_columns.append(\"Last Vote Date\")\n",
    "\n",
    "with open(FEATURES_FILE, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"demographic\": demographic_columns,\n",
    "            \"elections\": election_column_names,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "all_column_names = demographic_columns + election_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading\n",
    "\n",
    "Now, we're ready to actually read and process the county data. The code is well documented, but at a high level, we read in a county, extract all its files from the raw data, align the demographic and election data columns to the ones we've defined above, and write the county's data to a csv file.\n",
    "\n",
    "We don't aggregate all the counties together, since it would use too much RAM. With about 10,000,000 voters, the dataset would take 6 - 12 GB of RAM. Instead, we'll ensure alignment of the columns and then save them individually, so we can easily combine them later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for county in tqdm(\n",
    "    sorted(counties), desc=\"Processing counties\", unit=\"county\", colour=\"green\"\n",
    "):\n",
    "    # region Load the data\n",
    "    voter_data = election_map = zone_codes = zone_types = None\n",
    "    for file in os.listdir(VOTER_FILE_DIR):\n",
    "        if county in file and VOTER_FILE_STR in file:\n",
    "            voter_data = pd.read_csv(\n",
    "                os.path.join(VOTER_FILE_DIR, file),\n",
    "                sep=\"\\t\",\n",
    "                encoding=\"unicode_escape\",\n",
    "                header=None,\n",
    "                dtype=str,\n",
    "            )\n",
    "        if county in file and ELECTION_MAP_STR in file:\n",
    "            election_map = pd.read_csv(\n",
    "                os.path.join(VOTER_FILE_DIR, file),\n",
    "                sep=\"\\t\",\n",
    "                encoding=\"unicode_escape\",\n",
    "                header=None,\n",
    "            )\n",
    "\n",
    "            # Map the election number to a date in the elections\n",
    "            county_elections = {}\n",
    "            for _, row in election_map.iterrows():\n",
    "                date = row[3]\n",
    "                if date in date_to_names:\n",
    "                    county_elections[row[1]] = date\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Skipping election {row[1]} in county {county} due to missing data\"\n",
    "                    )\n",
    "\n",
    "        if county in file and ZONE_CODES_STR in file:\n",
    "            zone_codes = pd.read_csv(\n",
    "                os.path.join(VOTER_FILE_DIR, file),\n",
    "                sep=\"\\t\",\n",
    "                encoding=\"unicode_escape\",\n",
    "                header=None,\n",
    "            )\n",
    "        if county in file and ZONE_TYPES_STR in file:\n",
    "            zone_types = pd.read_csv(\n",
    "                os.path.join(VOTER_FILE_DIR, file),\n",
    "                sep=\"\\t\",\n",
    "                encoding=\"unicode_escape\",\n",
    "                header=None,\n",
    "            )\n",
    "\n",
    "    if voter_data is None or county_elections is None:\n",
    "        print(f\"Skipping county {county} due to missing data\")\n",
    "        continue\n",
    "    # endregion\n",
    "\n",
    "    voter_data.columns = columns_template[\"Field Description\"].tolist()\n",
    "\n",
    "    aligned_voter_data = pd.DataFrame(columns=all_column_names)\n",
    "\n",
    "    # region Migrate the demographic columns\n",
    "    for col in voter_data.columns:\n",
    "        # Ignore the election columns\n",
    "        if \"Election\" in col:\n",
    "            continue\n",
    "\n",
    "        elif col == \"Gender\":\n",
    "            aligned_voter_data[\"Gender M\"] = (voter_data[col] == \"M\").astype(int)\n",
    "            aligned_voter_data[\"Gender F\"] = (voter_data[col] == \"F\").astype(int)\n",
    "            aligned_voter_data[\"Gender U\"] = (~voter_data[col].isin([\"M\", \"F\"])).astype(\n",
    "                int\n",
    "            )\n",
    "\n",
    "        elif col == \"Party Code\":\n",
    "            aligned_voter_data[\"Party D\"] = (voter_data[col] == \"D\").astype(int)\n",
    "            aligned_voter_data[\"Party R\"] = (voter_data[col] == \"R\").astype(int)\n",
    "            aligned_voter_data[\"Party I\"] = (~voter_data[col].isin([\"D\", \"R\"])).astype(\n",
    "                int\n",
    "            )\n",
    "\n",
    "        # Scale all dates to 0-1 (using 1900 to today as range)\n",
    "        elif col in [\n",
    "            \"DOB\",\n",
    "            \"Registration Date\",\n",
    "            \"Status Change Date\",\n",
    "            \"Date Last Changed\",\n",
    "        ]:\n",
    "            date = pd.to_datetime(voter_data[col], errors=\"coerce\", format=\"%m/%d/%Y\")\n",
    "            today = pd.to_datetime(\"today\")\n",
    "            start_date = pd.to_datetime(\"1900-01-01\")\n",
    "\n",
    "            # If date is before start or after today, set to start or today\n",
    "            date = date.where(date > start_date, start_date)\n",
    "            date = date.where(date < today, today)\n",
    "\n",
    "            # In these columns, there are very few missing values, so we can just fill them with the start date\n",
    "            date = date.fillna(start_date)\n",
    "\n",
    "            aligned_voter_data[col] = round(\n",
    "                (date - start_date) / (today - start_date), 3\n",
    "            )\n",
    "\n",
    "        # Scale all dates (which may or may not exist) to 0-1\n",
    "        elif col == \"Last Vote Date\":\n",
    "            date = pd.to_datetime(voter_data[col], errors=\"coerce\", format=\"%m/%d/%Y\")\n",
    "            today = pd.to_datetime(\"today\")\n",
    "            start_date = pd.to_datetime(\"1900-01-01\")\n",
    "\n",
    "            # If date is before start or after today, set to start or today\n",
    "            date = date.where(date > start_date, start_date)\n",
    "            date = date.where(date < today, today)\n",
    "\n",
    "            aligned_voter_data[\"Last Vote Date Presence\"] = (~date.isna()).astype(int)\n",
    "\n",
    "            date = date.fillna(start_date)\n",
    "\n",
    "            aligned_voter_data[\"Last Vote Date\"] = round(\n",
    "                (date - start_date) / (today - start_date), 3\n",
    "            )\n",
    "\n",
    "        elif col == \"Voter Status\":\n",
    "            aligned_voter_data[col] = (voter_data[col] == \"A\").astype(int)\n",
    "\n",
    "        # Migrate the non-custom columns\n",
    "        elif col in all_column_names:\n",
    "            aligned_voter_data[col] = voter_data[col]\n",
    "\n",
    "        elif col in WITHHELD_DEMOGRAPHIC_FEATURES or \"District\" in col:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            print(f\"Found a missing column {col} in county {county}\")\n",
    "            aligned_voter_data[col] = None\n",
    "    # endregion\n",
    "\n",
    "    added_dates: set[str] = set()\n",
    "\n",
    "    # region Migrate the election columns\n",
    "    for index, election_date in county_elections.items():\n",
    "        if election_date in added_dates:\n",
    "            # This election was already added, so merge the features with the existing ones\n",
    "            aligned_voter_data[\n",
    "                f\"Election {election_date} Party D\"\n",
    "            ] = aligned_voter_data[f\"Election {election_date} Party D\"].combine_first(\n",
    "                voter_data[f\"Election {index} Party\"] == \"D\"\n",
    "            )\n",
    "            aligned_voter_data[\n",
    "                f\"Election {election_date} Party R\"\n",
    "            ] = aligned_voter_data[f\"Election {election_date} Party R\"].combine_first(\n",
    "                voter_data[f\"Election {index} Party\"] == \"R\"\n",
    "            )\n",
    "            aligned_voter_data[\n",
    "                f\"Election {election_date} Party I\"\n",
    "            ] = aligned_voter_data[f\"Election {election_date} Party I\"].combine_first(\n",
    "                ~voter_data[f\"Election {index} Party\"].isin([\"D\", \"R\"])\n",
    "            )\n",
    "            aligned_voter_data[f\"Election {election_date} Voted\"] = aligned_voter_data[\n",
    "                f\"Election {election_date} Voted\"\n",
    "            ].combine_first(\n",
    "                voter_data[f\"Election {index} Vote Method\"]\n",
    "                .isin([\"AP\", \"MB\", \"AB\", \"P\"])\n",
    "                .astype(int)\n",
    "            )\n",
    "            aligned_voter_data[\n",
    "                f\"Election {election_date} By Mail\"\n",
    "            ] = aligned_voter_data[f\"Election {election_date} By Mail\"].combine_first(\n",
    "                voter_data[f\"Election {index} Vote Method\"]\n",
    "                .isin([\"MB\", \"AB\"])\n",
    "                .astype(int)\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        aligned_voter_data[f\"Election {election_date} Party D\"] = (\n",
    "            voter_data[f\"Election {index} Party\"] == \"D\"\n",
    "        ).astype(int)\n",
    "        aligned_voter_data[f\"Election {election_date} Party R\"] = (\n",
    "            voter_data[f\"Election {index} Party\"] == \"R\"\n",
    "        ).astype(int)\n",
    "        aligned_voter_data[f\"Election {election_date} Party I\"] = (\n",
    "            ~voter_data[f\"Election {index} Party\"].isin([\"D\", \"R\"])\n",
    "        ).astype(int)\n",
    "        aligned_voter_data[f\"Election {election_date} Voted\"] = (\n",
    "            voter_data[f\"Election {index} Vote Method\"]\n",
    "            .isin([\"AP\", \"MB\", \"AB\", \"P\"])\n",
    "            .astype(int)\n",
    "        )\n",
    "        aligned_voter_data[f\"Election {election_date} By Mail\"] = (\n",
    "            voter_data[f\"Election {index} Vote Method\"].isin([\"MB\", \"AB\"]).astype(int)\n",
    "        )\n",
    "        aligned_voter_data[f\"Election {election_date} Presence\"] = 1\n",
    "\n",
    "        added_dates.add(election_date)\n",
    "    # endregion\n",
    "\n",
    "    # For all the elections that are not present, set the presence to 0\n",
    "    for election_date in date_to_names.keys():\n",
    "        if election_date not in added_dates:\n",
    "            aligned_voter_data[f\"Election {election_date} Presence\"] = 0\n",
    "\n",
    "    # Save the csv\n",
    "    aligned_voter_data.to_csv(\n",
    "        f\"{PROCESSED_DATA_DIR}/{county}_voter_data.csv\", index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Finally (and this part can be run independently of the rest of the script if needed), let's sample all the data to get a smaller dataset to work with. Edit the `SAMPLE_RATE` constant at the top of the code to change the proportion. This is how we'll do our EDA, and if needed, training.\n",
    "\n",
    "Note that this will take a while to run, since it involves reading in all the data and combining it. Also beware to limit the sample rate: if it were 1.0, it would take up 6 - 12 GB of RAM as mentioned above (since it would be the full dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 0.1\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(\n",
    "    os.listdir(PROCESSED_DATA_DIR), desc=\"Reading files\", unit=\"file\", colour=\"green\"\n",
    "):\n",
    "    if file.endswith(\".csv\"):\n",
    "        if file == TEN_PCT_SAMPLE_FILE:\n",
    "            # If this script was already run, skip the file\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, file))\n",
    "\n",
    "            # Take a random sample of 10% of the rows\n",
    "            df = df.sample(frac=SAMPLE_RATE, random_state=42)\n",
    "            dataframes.append(df)\n",
    "\n",
    "print(\"Combining dataframes (this could take a while)...\")\n",
    "df = pd.concat(dataframes, axis=0, ignore_index=True, sort=False)\n",
    "df.to_csv(TEN_PCT_SAMPLE_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from config import (\n",
    "    MAJOR_ELECTIONS_DATES_FILE,\n",
    "    TEN_PCT_SAMPLE_FILE,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    FEATURES_FILE,\n",
    "    election_date_to_feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|\u001b[32m██████████\u001b[0m| 70/70 [02:01<00:00,  1.73s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/04/2003: has 1860273 samples and 19.67% existance\n",
      "04/27/2004: has 3437031 samples and 36.35% existance\n",
      "11/02/2004: has 4484242 samples and 47.42% existance\n",
      "05/17/2005: has 6635385 samples and 70.17% existance\n",
      "11/08/2005: has 7313625 samples and 77.34% existance\n",
      "05/16/2006: has 7343628 samples and 77.66% existance\n",
      "11/07/2006: has 7343628 samples and 77.66% existance\n",
      "05/15/2007: has 8471785 samples and 89.59% existance\n",
      "11/06/2007: has 8471785 samples and 89.59% existance\n",
      "04/22/2008: has 9456662 samples and 100.00% existance\n",
      "11/04/2008: has 9456662 samples and 100.00% existance\n",
      "05/19/2009: has 9456662 samples and 100.00% existance\n",
      "11/03/2009: has 9456662 samples and 100.00% existance\n",
      "05/18/2010: has 9456662 samples and 100.00% existance\n",
      "11/02/2010: has 9456662 samples and 100.00% existance\n",
      "05/17/2011: has 9456662 samples and 100.00% existance\n",
      "11/08/2011: has 9456662 samples and 100.00% existance\n",
      "04/24/2012: has 9456662 samples and 100.00% existance\n",
      "11/06/2012: has 9456662 samples and 100.00% existance\n",
      "05/21/2013: has 9456662 samples and 100.00% existance\n",
      "11/05/2013: has 9456662 samples and 100.00% existance\n",
      "05/20/2014: has 9456662 samples and 100.00% existance\n",
      "11/04/2014: has 9456662 samples and 100.00% existance\n",
      "05/19/2015: has 9456662 samples and 100.00% existance\n",
      "11/03/2015: has 9456662 samples and 100.00% existance\n",
      "04/26/2016: has 9456662 samples and 100.00% existance\n",
      "11/08/2016: has 9456662 samples and 100.00% existance\n",
      "05/16/2017: has 9456662 samples and 100.00% existance\n",
      "11/07/2017: has 9456662 samples and 100.00% existance\n",
      "05/15/2018: has 9456662 samples and 100.00% existance\n",
      "11/06/2018: has 9456662 samples and 100.00% existance\n",
      "05/21/2019: has 9456662 samples and 100.00% existance\n",
      "11/05/2019: has 9456662 samples and 100.00% existance\n",
      "06/02/2020: has 9456662 samples and 100.00% existance\n",
      "11/03/2020: has 9456662 samples and 100.00% existance\n",
      "05/18/2021: has 9456662 samples and 100.00% existance\n",
      "11/02/2021: has 9456662 samples and 100.00% existance\n",
      "05/17/2022: has 9456662 samples and 100.00% existance\n",
      "11/08/2022: has 9456662 samples and 100.00% existance\n",
      "05/16/2023: has 9456662 samples and 100.00% existance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the percent of all samples which have each election date\n",
    "\n",
    "major_elections = json.load(open(MAJOR_ELECTIONS_DATES_FILE))[\"dates\"]\n",
    "\n",
    "num_total = 0\n",
    "num_sampled = [0] * len(major_elections)\n",
    "\n",
    "for file in tqdm(\n",
    "    os.listdir(PROCESSED_DATA_DIR), desc=\"Reading files\", unit=\"file\", colour=\"green\"\n",
    "):\n",
    "    if file.endswith(\".csv\"):\n",
    "        if file == TEN_PCT_SAMPLE_FILE:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, file))\n",
    "\n",
    "            num_total += len(df)\n",
    "\n",
    "            for date in major_elections:\n",
    "                presence_column = f\"Election {date} Presence\"\n",
    "\n",
    "                if presence_column in df.columns:\n",
    "                    num_sampled[major_elections.index(date)] += df[presence_column].sum()\n",
    "\n",
    "for i in range(len(major_elections)):\n",
    "    print(f\"{major_elections[i]}: has {num_sampled[i]} samples and {num_sampled[i] / num_total * 100:.2f}% existance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've decided which election years to use (2008 Primary through 2023 General) by thresholding the existance rate at 100%. We are left with 30 elections, for which we'll use 10 sliding windows of 20 features (10 years) each (and 1 response variable).\n",
    "\n",
    "Now, we will build a full dataset, sampling from the data for each model. Optimally, we would sample the full dataset on each sliding window (thus, a 100% sample), but this would result in about 100,000,000 samples. To balance computational cost, we'll sample 10% of the data for now, which will result in about 10,000,000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_election_dates = json.load(open(MAJOR_ELECTIONS_DATES_FILE))[\"feature_dates\"]\n",
    "\n",
    "demographic_features = json.load(open(FEATURES_FILE))[\"demographic\"]\n",
    "\n",
    "# Allow for 10 years of election history and 1 response variable election\n",
    "SLIDING_WINDOW_LENGTH = 21\n",
    "num_sliding_windows = len(feature_election_dates) - SLIDING_WINDOW_LENGTH + 1\n",
    "\n",
    "# Use the feature names \"T - 1\", \"T - 2\", etc. for the feature elections\n",
    "universal_election_column_names = [\n",
    "    f\"T-{i}\" for i in range(SLIDING_WINDOW_LENGTH - 1, 0, -1)\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(columns=demographic_features + universal_election_column_names + [\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed this up, let's pickle every county's processed data, so that when we need to read it in for each sample, it takes much less time (note that other approaches which require reading in all the data at once, or reading in each county's data once for all samples, would require too much RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, read in the data and sample for each sliding window\n",
    "for i in range(num_sliding_windows):\n",
    "    # Gather the election features for the current sliding window\n",
    "    election_columns = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            election_date_to_feature_names(date)\n",
    "            for date in feature_election_dates[i : i + SLIDING_WINDOW_LENGTH - 1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Gather the response variable election for the current sliding window\n",
    "    response_column = f\"Election {feature_election_dates[i + SLIDING_WINDOW_LENGTH - 1]} Presence\"\n",
    "\n",
    "    # Read in the data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import (FEATURES_FILE, MAJOR_ELECTIONS_DATES_FILE,\n",
    "                    PROCESSED_DATA_DIR, SLIDING_WINDOW_FILE,\n",
    "                    TEN_PCT_SAMPLE_FILE, election_date_to_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|\u001b[32m██████████\u001b[0m| 70/70 [02:01<00:00,  1.73s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/04/2003: has 1860273 samples and 19.67% existance\n",
      "04/27/2004: has 3437031 samples and 36.35% existance\n",
      "11/02/2004: has 4484242 samples and 47.42% existance\n",
      "05/17/2005: has 6635385 samples and 70.17% existance\n",
      "11/08/2005: has 7313625 samples and 77.34% existance\n",
      "05/16/2006: has 7343628 samples and 77.66% existance\n",
      "11/07/2006: has 7343628 samples and 77.66% existance\n",
      "05/15/2007: has 8471785 samples and 89.59% existance\n",
      "11/06/2007: has 8471785 samples and 89.59% existance\n",
      "04/22/2008: has 9456662 samples and 100.00% existance\n",
      "11/04/2008: has 9456662 samples and 100.00% existance\n",
      "05/19/2009: has 9456662 samples and 100.00% existance\n",
      "11/03/2009: has 9456662 samples and 100.00% existance\n",
      "05/18/2010: has 9456662 samples and 100.00% existance\n",
      "11/02/2010: has 9456662 samples and 100.00% existance\n",
      "05/17/2011: has 9456662 samples and 100.00% existance\n",
      "11/08/2011: has 9456662 samples and 100.00% existance\n",
      "04/24/2012: has 9456662 samples and 100.00% existance\n",
      "11/06/2012: has 9456662 samples and 100.00% existance\n",
      "05/21/2013: has 9456662 samples and 100.00% existance\n",
      "11/05/2013: has 9456662 samples and 100.00% existance\n",
      "05/20/2014: has 9456662 samples and 100.00% existance\n",
      "11/04/2014: has 9456662 samples and 100.00% existance\n",
      "05/19/2015: has 9456662 samples and 100.00% existance\n",
      "11/03/2015: has 9456662 samples and 100.00% existance\n",
      "04/26/2016: has 9456662 samples and 100.00% existance\n",
      "11/08/2016: has 9456662 samples and 100.00% existance\n",
      "05/16/2017: has 9456662 samples and 100.00% existance\n",
      "11/07/2017: has 9456662 samples and 100.00% existance\n",
      "05/15/2018: has 9456662 samples and 100.00% existance\n",
      "11/06/2018: has 9456662 samples and 100.00% existance\n",
      "05/21/2019: has 9456662 samples and 100.00% existance\n",
      "11/05/2019: has 9456662 samples and 100.00% existance\n",
      "06/02/2020: has 9456662 samples and 100.00% existance\n",
      "11/03/2020: has 9456662 samples and 100.00% existance\n",
      "05/18/2021: has 9456662 samples and 100.00% existance\n",
      "11/02/2021: has 9456662 samples and 100.00% existance\n",
      "05/17/2022: has 9456662 samples and 100.00% existance\n",
      "11/08/2022: has 9456662 samples and 100.00% existance\n",
      "05/16/2023: has 9456662 samples and 100.00% existance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the percent of all samples which have each election date\n",
    "\n",
    "major_elections = json.load(open(MAJOR_ELECTIONS_DATES_FILE))[\"dates\"]\n",
    "\n",
    "num_total = 0\n",
    "num_sampled = [0] * len(major_elections)\n",
    "\n",
    "for file in tqdm(\n",
    "    os.listdir(PROCESSED_DATA_DIR), desc=\"Reading files\", unit=\"file\", colour=\"green\"\n",
    "):\n",
    "    if file.endswith(\".csv\"):\n",
    "        if file == TEN_PCT_SAMPLE_FILE:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, file))\n",
    "\n",
    "            num_total += len(df)\n",
    "\n",
    "            for date in major_elections:\n",
    "                presence_column = f\"Election {date} Presence\"\n",
    "\n",
    "                if presence_column in df.columns:\n",
    "                    num_sampled[major_elections.index(date)] += df[presence_column].sum()\n",
    "\n",
    "for i in range(len(major_elections)):\n",
    "    print(f\"{major_elections[i]}: has {num_sampled[i]} samples and {num_sampled[i] / num_total * 100:.2f}% existance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've decided which election years to use (2008 Primary through 2023 General) by thresholding the existance rate at 100%. We are left with 30 elections, for which we'll use 10 sliding windows of 20 features (10 years) each (and 1 response variable).\n",
    "\n",
    "Now, we will build a full dataset, sampling from the data for each model. Optimally, we would sample the full dataset on each sliding window (thus, a 100% sample), but this would result in about 100,000,000 samples. To balance computational cost, we'll sample 10% of the data for now, which will result in about 10,000,000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_election_dates = json.load(open(MAJOR_ELECTIONS_DATES_FILE))[\"feature_dates\"]\n",
    "\n",
    "demographic_features = json.load(open(FEATURES_FILE))[\"demographic\"]\n",
    "\n",
    "# Allow for 10 years of election history and 1 response variable election\n",
    "SLIDING_WINDOW_LENGTH = 21\n",
    "num_sliding_windows = len(feature_election_dates) - SLIDING_WINDOW_LENGTH + 1\n",
    "\n",
    "# Use the election names \"T - 1\", \"T - 2\", etc. for the feature elections\n",
    "# However, we've decided to only use elections which have 100% presence, so \"Presence\" columns are redundant\n",
    "sliding_election_column_names = list(\n",
    "    itertools.chain.from_iterable(\n",
    "        [\n",
    "            [feat for feat in election_date_to_feature_names(f\"T-{i}\") if \"Presence\" not in feat]\n",
    "            for i in range(SLIDING_WINDOW_LENGTH - 1, 0, -1)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove the features which would cause leakage in the sliding window approach\n",
    "sliding_demographic_features = [feature for feature in demographic_features if \"Gender\" in feature]\n",
    "\n",
    "sliding_features = sliding_demographic_features + sliding_election_column_names + [\"Response\"]\n",
    "\n",
    "df = pd.DataFrame(columns=sliding_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've removed some demographic features for this sliding window approach. For example, `Registration Date`, `Last Vote Date`, etc. have been removed. Most importantly, `DOB` has been removed. For all these features, including them would require, for each sample, re-calculating their expected value (for those like `Last Vote Date`), and then calculating their value. For `DOB`, the age of the voter should be adjusted for each election year. For this version, we have left this out in the interest of testing general model ability on this data. However, we plan to include it in our final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|\u001b[32m██████████\u001b[0m| 72/72 [02:08<00:00,  1.78s/file]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Now, read in the data and sample for each sliding window\n",
    "for i, file in enumerate(tqdm(\n",
    "    os.listdir(PROCESSED_DATA_DIR), desc=\"Reading files\", unit=\"file\", colour=\"green\"\n",
    ")):\n",
    "    if file.endswith(\".csv\"):\n",
    "        if file == TEN_PCT_SAMPLE_FILE:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, file))\n",
    "\n",
    "            # Sample each sliding window\n",
    "            for i in range(num_sliding_windows):\n",
    "                # Gather the election features for the current sliding window\n",
    "                election_columns = list(\n",
    "                    itertools.chain.from_iterable(\n",
    "                        [feat for feat in election_date_to_feature_names(date) if \"Presence\" not in feat]\n",
    "                        for date in feature_election_dates[i : i + SLIDING_WINDOW_LENGTH - 1]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Gather the response variable election for the current sliding window\n",
    "                response_column = f\"Election {feature_election_dates[i + SLIDING_WINDOW_LENGTH - 1]} Voted\"\n",
    "\n",
    "                all_selected_columns = sliding_demographic_features + election_columns + [response_column]\n",
    "\n",
    "                # Sample the data\n",
    "                df_sample = df[all_selected_columns].sample(frac=0.01)\n",
    "                df_sample.columns = sliding_features\n",
    "\n",
    "                dfs.append(df_sample)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(SLIDING_WINDOW_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: For now, we've included voters in this dataset which were actually registered after the response election dates. For the next version, we will check the `DOB` and eliminate voters from the sample which could never have been in the voter file at that time. Note that there is still some bias introduced which we cannot overcome, from voters which have been eliminated from the file since the response election date. Those voters may have died or moved, but we'd like our model to still learn from them. The only solution to this is to request the voter files from those dates, which would (for us) be too time-consuming and expensive to be worth it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
